---
layout: project
urltitle:  "AI4Space 2022"
title: "AI4Space 2022"
categories: eccv, workshop, artificial intelligence, computer vision, space 
permalink: /
favicon: /static/img/ico/favicon.png
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row header-row" id="home">
  <div class="col-xs-12 header-img">  
    <center><h1 style="font-size:60px">AI4Space 2022</h1></center>
    <center><br></center>
    <center><br></center>
    <br>
    <br>
    <br>
    <center><h3 style="color:white">2nd Workshop on AI for Space</h3></center>
    <center><h3 style="color:white">In conjunction with <a href="https://eccv2022.ecva.net/">ECCV 2022</a></h3></center>    
    <center><h3 style="color:white">Date: TBD</h3></center>
    <!-- <center><span style="font-weight:400;">14th of June 2020</span></center> -->
    <br>
  </div>
</div>

<hr>

<!-- <div class="row" id="">
  <div class="col-md-12">
    <img src="{{ "/static/img/splash.png" | prepend:site.baseurl }}">
    <p> Image credit: [1, 2, 7, 12, 6, 4, 5]</p>
  </div>
</div> -->

<!-----
<br>
<div class="row" id="">
  <div class="col-xs-12">
    <center><h2 style="font-size:30px"><a href="#program">Watch workshop videos</a></h2></center>
  </div>
</div>
----->

<br>
<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row" style="text-align:center">

  <div class="col-xs-2">
    <a href="https://cs.adelaide.edu.au/~tjchin">
      <img class="people-pic" src="{{ "/static/img/people/tj.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://cs.adelaide.edu.au/~ssl">Tat-Jun Chin</a>
      <h6>The University of Adelaide</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://lucacarlone.mit.edu/">
      <img class="people-pic" src="{{ "/static/img/people/luca.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://lucacarlone.mit.edu/">Luca Carlone</a>
      <h6>Massachusetts Institute of Technology</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://cvi2.uni.lu//">
      <img class="people-pic" src="{{ "/static/img/people/djamila.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://cvi2.uni.lu/">Djamila Aouada</a>
      <h6>University of Luxembourg</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://teacher.nwpu.edu.cn/m/en/2011010003.html">
      <img class="people-pic" src="{{ "/static/img/people/binfeng.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://teacher.nwpu.edu.cn/m/en/2011010003.html">Binfeng Pan</a>
      <h6>Northwestern Polytechnical University</h6>
    </div>
  </div>


  
  </div>
  
  
  <div class="row">
  
  <div class="col-xs-2">
    <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/viorela-ila.html">
      <img class="people-pic" src="{{ "/static/img/people/viorela.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/viorela-ila.html">Viorela Ila</a>
      <h6>The University of Sydney</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <a href="https://www-robotics.jpl.nasa.gov/who-we-are/people/benjamin_morrell/">
      <img class="people-pic" src="{{ "/static/img/people/ben.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www-robotics.jpl.nasa.gov/who-we-are/people/benjamin_morrell/">Benjamin Morrell</a>
      <h6>NASA Jet Propulsion Lab</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <a href="https://g-kakareko.github.io/index.html">
      <img class="people-pic" src="{{ "/static/img/people/grzegorz.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://g-kakareko.github.io/index.html">Grzegorz Kakareko</a>
      <h6>Spire Global</h6>
    </div>
  </div>   
  
  <div class="col-xs-2">
    <!---<a href="">--->
      <img class="people-pic" src="{{ "/static/img/people/sofia.jpeg" | prepend:site.baseurl }}">
    <!---</a>--->
    <div class="people-name">
      <a href="">Sofia Mcleod</a>
      <h6>The University of Adelaide</h6>
    </div>
  </div>  
  
</div>


<div class="row" id="intro">
  <div class="col-xs-12">
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
        <p>
            The space sector is experiencing significant growth. Currently planned activities and utilisation models also greatly exceed the scope, ambition and/or commercial value of space missions in the previous century, e.g., autonomous spacecraft, space mining, and understanding the universe. Achieving these ambitious goals requires surmounting non-trivial technical obstacles. AI4Space focuses on the role of AI, particularly computer vision and machine learning, in helping to solve those technical hurdles. The workshop will highlight the space capabilities that draw from and/or overlap significantly with vision and learning research, outline the unique difficulties presented by space applications to vision and learning, and discuss recent advances towards overcoming those obstacles.
        </p>
  </div>
</div><br>

<!----
<div class="row">
    <div class="col-xs-12">
        <p>
            <h2>Sponsors</h2>
        </p>
        <div class="col-xs-4">
            <a href="#sponsors"><img class="people-pic-big" src="{{ "/static/img/sponsors/draper.png" | prepend:site.baseurl }}"></a>
        </div>
        <div class="col-xs-4">
            <a href="#sponsors"><img class="people-pic-big" src="{{ "/static/img/sponsors/blackswan.png" | prepend:site.baseurl }}"></a>
        </div>
        <div class="col-xs-4">
            <a href="#sponsors"><img class="people-pic-big" src="{{ "/static/img/sponsors/asa.png" | prepend:site.baseurl }}"></a>
        </div>
    </div>
    <p>
        <div class="col-xs-9">
             <p>
                <h2>Affiliated organisations</h2>
             </p>
             <p>
                 <div class="col-xs-4">
                     <a href="#organisations"><img class="people-pic" src="{{ "/static/img/sponsors/esa2.png" | prepend:site.baseurl }}"></a>
                 </div>
                 <div class="col-xs-4">
                     <a href="#organisations"><img class="people-pic" src="{{ "/static/img/sponsors/act2.png" | prepend:site.baseurl }}"></a>
                 </div>
                 <div class="col-xs-4">
                     <a href="#sponsors"><img class="people-pic" src="{{ "/static/img/sponsors/smartsat2.png" | prepend:site.baseurl }}"></a>
                 </div>
             </p>
         </div>
     </p>
</div><br>
--->

<!---
<div class="row">
    <div class="col-xs-12">
        <p>
            <h2>Sponsors</h2>      
            TBD
        </p>
    </div>
    <p>
        <div class="col-xs-9">
             <p>
                <h2>Affiliated organisations</h2>
                TBD
             </p>
         </div>
     </p>
</div><br>
--->

<!----
<div class="row" id="program">
  <div class="col-xs-12">
    <h2>Workshop Program</h2>
    TBD
  </div>
</div>
--->

<!----
<div class="row">
 <div class="col-xs-12">
  <h3>Watch the video recordings of <a href="https://youtu.be/j83aOI0suuo"><b>Block A</b></a> and <a href="https://youtu.be/oadmxrgiE1g"><b>Block B</b></a> on YouTube.</h3>
 </div>
</div>
<br>

<div class="row">
  <div class="col-xs-12">
    <h3>Block A (<a href="/2021/static/AI4Space Program (Block A).ics" download><b>download calendar</b></a> to add program to your calendar)</h3>
    <table class="table table-striped">
      <tbody>
        <tr>
            <th>Europe (Central)<br>19 June 2021</th>
            <th>Australia (Sydney)<br>20 June 2021</th>
            <th>N. America (East)<br>19 June 2021</th>
            <th>Activity</th>
        </tr>
        <tr>
          <td>16:00</td>
          <td>00:00</td>
          <td>10:00</td>          
          <td>Welcome address</td>
        </tr>
        <tr>
          <td>16:05</td>
          <td>00:05</td>
          <td>10:05</td>          
          <td>Keynote 1: <a href="#Shirley">Shirley Ho</a></td>
        </tr>
        <tr>
          <td>16:35</td>
          <td>00:35</td>
          <td>10:35</td>          
          <td>Keynote 2: <a href="#Courtney">Courtney Mario</a><br>Developing Vision Navigation Systems for Space Applications and Lessons Learned from OSIRIS-REx</td>
        </tr>
        <tr>
          <td>17:05</td>
          <td>01:05</td>
          <td>11:05</td>          
          <td>Intro to MDS Software (Blackswan Technologies)</td>
        </tr>
        <tr>
          <td>17:20</td>
          <td>01:20</td>
          <td>11:20</td>          
          <td>Spotlight presentations<br>5 mins per paper<br> <a href="#papers_a">List of papers</a></td>
        </tr>
        <tr>
          <td>18:00</td>
          <td>02:00</td>
          <td>12:00</td>          
          <td>Poster session<br>Presented using Gatherly</td>
        </tr>
        <tr>
          <td>18:20</td>
          <td>02:20</td>
          <td>12:20</td>          
          <td>Award announcements</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <h3>Block B (<a href="/2021/static/AI4Space Program (Block B).ics" download><b>download calendar</b></a> to add program to your calendar)</h3>
    <table class="table table-striped">
      <tbody>
        <tr>
            <th>Europe (Central)<br>20 June 2021</th>
            <th>Australia (Sydney)<br>20 June 2021</th>
            <th>N. America (East)<br>20 June 2021</th>
            <th>Activity</th>
        </tr>
        <tr>
          <td>09:00</td>
          <td>17:00</td>
          <td>03:00</td>          
          <td>Welcome address</td>
        </tr>
        <tr>
          <td>09:05</td>
          <td>17:05</td>
          <td>03:05</td>          
          <td>Keynote 3: <a href="#Dario">Dario Izzo</a><br>Emerging trends in ``deep space learning"</td>
        </tr>
        <tr>
          <td>09:35</td>
          <td>17:35</td>
          <td>03:35</td>          
          <td>Keynote 4: <a href="#Yang">Yang Gao</a><br>AI Robotics for Sustainable Space Exploration & Exploitation</td>
        </tr>
        <tr>
          <td>10:05</td>
          <td>18:05</td>
          <td>04:05</td>          
          <td>Spotlight presentations<br>5 mins per paper<br><a href="#papers_b">List of papers</a></td>
        </tr>
        <tr>
          <td>10:50</td>
          <td>18:50</td>
          <td>04:50</td>          
          <td>Poster session<br>Presented using Gatherly</td>
        </tr>
        <tr>
          <td>11:10</td>
          <td>19:10</td>
          <td>05:10</td>          
          <td>Award announcements and conclusion</td>
        </tr>
      </tbody>
    </table>
  </div>
</div><br>
---->

<!----
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
    TBD
  </div>
</div><br>
--->

<!-- 26 -->
<!-----
<div class="row">
  <div class="col-md-12" id="Shirley">
    <a href="https://www.simonsfoundation.org/team/shirley-ho/"><img class="people-pic-big" style="float:left;margin-right:30px;" src="{{ "/static/img/speakers/shirley.png" | prepend:site.baseurl }}"></a>
    <p>
      <b><a href="https://www.simonsfoundation.org/team/shirley-ho/">Shirley Ho</a></b> is Leader of the Cosmology X Data Science group at the Center for Computational Astrophysics (CCA), Flatiron Institute. Her research interests range from fundamental cosmological measurements to exoplanet statistics to using machine learning to estimate how much dark matter is in the universe. Her goal is to understand the universe’s beginning, evolution and its ultimate fate. Recently she has been developing novel tools using machine learning to solve astrophysical challenges. Shirley plans, builds and analyzes data from a number of astronomical surveys such as Actacama Cosmology Telescope, Euclid, the Large Synoptic Survey Telescope, Simons Observatory, Sloan Digital Sky Survey and the Wide Field Infrared Survey Telescope. She has broad expertise in theory, observation and data science, and her significant experience on machine learning for cosmology will deliver plenty of insights to the CVPR audience. Shirley earned her Ph.D. in astrophysical sciences from Princeton in 2008 and her bachelor’s degrees in computer science and physics from the UC Berkeley in 2004. She was a Chamberlain fellow and a Seaborg fellow at Lawrence Berkeley National Laboratory before joining CMU in 2011 as an assistant professor. She became the Cooper Siegel Career Development Chair Professor and was appointed associate professor with tenure in 2016. She moved to Lawrence Berkeley Lab as a Senior Scientist in 2016. Since 2011, she has been a primary mentor to more than 25 postdoctoral fellows, seven graduate students and 20 undergraduates.
    </p>
  </div>
</div><br>
--->

<!-- 24 -->
<!-----
<div class="row">
  <div class="col-md-12" id="Courtney">
    <a href="https://www.linkedin.com/in/courtneymario"><img class="people-pic-big" style="float:left;margin-right:30px;" src="{{ "/static/img/speakers/courtney.jpg" | prepend:site.baseurl }}"></a>
    <p>
      <b><a href="https://www.linkedin.com/in/courtneymario">Courtney Mario</a></b> is a Principal Member of the Technical Staff at The Charles Stark Draper Laboratory (Draper) in the Perception and Autonomy Group. Draper is a not-for-profit R&D organization headquartered in Cambridge, Massachusetts. The lab specializes in the design, development, and deployment of advanced technology solutions to problems in space exploration, health care and energy and was originally best known for providing the Apollo Guidance computer. She is a member of the Natural Feature Tracking team for OSIRIS-REx, NASA’s asteroid sample return mission that successfully autonomously navigated to the asteroid surface in October 2020 to collect the sample. She is also currently leading the algorithm development for Draper’s lunar precision landing capability. Prior work has included developing vision-inertial systems for GPS-denied applications for ground vehicles, UAVs, and pedestrians. Courtney has over ten years of experience in vision navigation systems for GPS-denied environments, and the lessons she has learnt on the challenges of visual navigation in the space environment will be extremely beneficial to the CVPR community. Courtney earned a Bachelor’s degree (graduated Magna Cum Laude) and Master’s degree in mechanical engineering, both from Tufts University.
    </p>
  </div>
</div><br>
---->

<!-- 23 -->
<!-----
<div class="row">
  <div class="col-md-12" id="Dario">
    <a href="https://www.esa.int/gsp/ACT/team/dario_izzo/"><img class="people-pic-big" style="float:left;margin-right:30px;" src="{{ "/static/img/speakers/dario.png" | prepend:site.baseurl }}"></a>
    <p>
      <b><a href="https://www.esa.int/gsp/ACT/team/dario_izzo/">Dario Izzo</a></b> is the Scientific Coordinator of the Advanced Concepts Team (ACT) at ESA, where he coordinates all the scientific activities of the ACT and manages the interface of the ACT to the rest of ESA. Dario is a major proponent of AI and champion of deep neural networks to solve space problems. He led studies in interplanetary trajectory design using AI and was responsible for starting the Global Trajectory Optimization Competitions events, the ESA’s Summer of Code in Space, and the Kelvins competition platform which brings together AI and space researchers. At the proposed workshop, Dario will be sharing his expertise and experience on AI algorithms for spacecraft guidance dynamics and control. Dario has published more than 150 papers in journals, conferences and books. In 2013, he received the Humies Gold Medal for the work on grand tours of the galilean moons and, the following year, he won the 8th edition of the Global Trajectory Optimization Competition, organized by NASA/JPL, leading a mixed team of ESA/JAXA scientists. Dario graduated in Aeronautical Engineering from the University Sapienza of Rome in 1999. He later obtained a second master in “Satellite Platforms” at the University of Cranfield in the UK and a Ph.D. in Mathematical Modelling in 2003, at the University Sapienza of Rome where he had the honour to assist Prof. Chiara Valente throughout the classical mechanics and space flight mechanics courses during the academic years 2001-2003.
    </p>
  </div>
</div><br>
--->

<!-- 16 -->
<!-----
<div class="row">
  <div class="col-md-12" id="Yang">
    <a href="https://www.surrey.ac.uk/people/yang-gao"><img class="people-pic-big" style="float:left;margin-right:30px;" src="{{ "/static/img/speakers/yang.jpg" | prepend:site.baseurl }}"></a>
    <p>
      <b><a href="https://www.surrey.ac.uk/people/yang-gao">Yang Gao</a></b> is the Professor of Space Autonomous Systems at Surrey Space Centre (SSC) and the Head of the STAR LAB which specializes in visual sensing and navigation in extreme environments. She has 20 years of research experience in developing robotics and autonomous systems, and has been funded by UK Research Innovation, Royal Academy of Engineering, European Commission, European Space Agency, UK Space Agency, as well as industrial companies such as Airbus, NEPTEC, Sellafield and OHB. Yang is also actively involved in the R&D real-world space missions, e.g., ESA's ExoMars, Proba3 and LUCE-ice mapper, UK's MoonLITE/Moonraker, and China's Chang'E 3. Her expertise in solving real-world space visual navigation problems will be of significant interest to the CVPR audience. Yang is an Elected Fellow of Institute of Engineering and Technology (IET) and Royal Aeronautical Society (RAeS). Her research work led to international acclaim, such as International Astronautical Federation’s 3AF Edmond Brun Silver Medal in 2013, COSPAR's Outstanding Paper Award in 2016, First Prize of UKSEDS Lunar Rover Competition in 2017, Finalist of IEEE/ASME's AIM Best Paper Award 2019 and First Prize of Best Poster Award at ICRA 2020 Space Robotics Workshop. Prior to joining SSC in 2004, Yang was an awardee of the prestigious Singapore Millennium Foundation (SMF) Postdoctoral Fellowship and worked on intelligent and autonomous vehicles. She gained the B.Eng. and Ph.D. degrees from the Nanyang Technological University in 2000 and 2003 respectively.
    </p>
  </div>
</div><br>
--->

<!-----
<div class="row" id="papers">
  <div class="col-xs-12">
    <h2>Accepted Papers</h2>
    <h3>Block A</h3>
    <table class="table table-striped" id="papers_a">
      <tbody>
        <tr>
          <th>
          Order of presentation
          </th>
          <th>
          Paper title and authors
          </th>        
        </tr>
        <tr>
          <td>
          1  <br> Stall A
          </td>
          <td>
          AI for dating stars: a benchmarking study for gyrochronology
          <br><em>Andres Moya, Jarmi Recio Martínez, Roberto Javier Lopez-Sastre</em>
          </td>
        </tr>
        <tr>
          <td>
          2  <br> Stall B
          </td>
          <td>Investigating Spiking Neural Networks for Energy-Efficient On-Board AI Applications. A Case Study in Land Cover and Land Use Classification
          <br><em>Andrzej S Kucik, Gabriele Meoni</em>
          </td>
        </tr>
        <tr>
          <td>
          3  <br> Stall C
          </td>
          <td>Autonomous Planetary Landing via Deep Reinforcement Learning and Transfer Learning
          <br><em>Giulia Ciabatti, Shreyansh Daftry, Roberto Capobianco</em>
          </td>
        </tr>
        <tr>
          <td>
          4  <br> Stall D
          </td>
          <td>Improving Astronomy Image Quality Through Real-time Wavefront Estimation
          <br><em>David Thomas, Joshua Meyers, Steven Kahn</em>
          </td>
        </tr>
        <tr>
          <td>
          5  <br> Stall E
          </td>
          <td>On-Orbit Inspection of an Unknown Tumbling Target using NASA's Astrobee Robotic Free-Flyers
          <br><em>Charles E Oestreich, Antonio Teran Espinoza, Jessica Todd, Keenan Albee, Richard Linares</em>
          </td>
        </tr>
        <tr>
          <td>
          6  <br> Stall F
          </td>
          <td>Spacecraft Time-Series Anomaly Detection Using Transfer Learning
          <br><em>Sriram Baireddy, Sundip Desai, James Mathieson, Richard Foster, Moses Chan, Mary Comer, Edward Delp</em>
          </td>
        </tr>
        <tr>
          <td>
          7  <br> Stall G
          </td>
          <td>SPACESeg: Automated Detection of Bed Junction Morphologies Indicating Signs of Life in Ediacaran Period
          <br><em>Padmaja Jonnalagedda, Rachel Surprenant, Mary Droser, Bir Bhanu</em>
          </td>
        </tr>
        <tr>
          <td>
          8  <br> Stall H
          </td>
          <td>Visual SLAM for Asteroid Relative Navigation
          <br><em>Mehregan Dor, Katherine A Skinner, Travis Driver, Panagiotis Tsiotras</em>
          </td>
        </tr>
      </tbody>
    </table>
    <h3>Block B</h3>
    <table class="table table-striped" id="papers_b">
      <tbody>
        <tr>
          <th>
          Order of presentation
          </th>
          <th>
          Paper title and authors
          </th>        
        </tr>
        <tr>
          <td>
          1  <br> Stall A
          </td>
          <td>A Monocular Pose Estimation Case Study: The Hayabusa2 Minerva-II2 Deployment
          <br><em>Andrew Price, Kazuya Yoshida</em>
          </td>
        </tr>
        <tr>
          <td>
          2  <br> Stall B
          </td>
          <td>A Spacecraft Dataset for Detection, Segmentation and Parts Recognition
          <br><em>Dung Anh Hoang, Bo Chen, Tat-Jun Chin</em>
          </td>
        </tr>
        <tr>
          <td>
          3  <br> Stall C
          </td>
          <td>Event-based spacecraft landing using time-to-contact
          <br><em>Olaf Sikorski, Dario Izzo, Gabriele Meoni</em>
          </td>
        </tr>
        <tr>
          <td>
          4  <br> Stall D
          </td>
          <td>From Rocks to Walls: a Model-free Reinforcement Learning Approach to Dry Stacking with Irregular Rocks
          <br><em>André Menezes, Pedro Vicente, Alexandre Bernardino, Rodrigo Ventura</em>
          </td>
        </tr>
        <tr>
          <td>
          5  <br> Stall E
          </td>
          <td>AI4MARS: A Dataset for Terrain-Aware Autonomous Driving on Mars
          <br><em>R. Michael Swan, Deegan J Atha, Henry A Leopold, Cindy Chiu, Matthew Gildner, Stephanie L Oij, Masahiro Ono</em>
          </td>
        </tr>
        <tr>
          <td>
          6 <br> Stall F
          </td>
          <td>LSPnet: A 2D Localization-oriented Spacecraft Pose Estimation Neural Network
          <br><em>Albert Garcia, Mohamed Adel Musallam, Vincent Gaudilliere, Enjie Ghorbel, Kassem Al Ismaeil, Marcos Perez, Djamila Aouada</em>
          </td>
        </tr>
        <tr>
          <td>
          7  <br> Stall G
          </td>
          <td>MRSCAtt: A Spatio-Channel Attention-Guided Network for Mars Rover Image Classification
          <br><em>Anirudh Srinivasan Chakravarthy, Roshan Roy, Praveen  Ravirathinam</em>
          </td>
        </tr>
        <tr>
          <td>
          8  <br> Stall H
          </td>
          <td>Spot the GEO Satellites: From Dataset to Kelvins SpotGEO Challenge
          <br><em>Bo Chen, Daqi Liu, Tat-Jun Chin, Mark Rutten, Dawa Derksen, Marcus Maertens, Moritz Von Looz, Gurvan Lecuyer, Dario Izzo</em>
          </td>
        </tr>
        <tr>
          <td>
          9 <br> Stall I
          </td>
          <td>Vision-based Neural Scene Representations for Spacecraft
          <br><em>Anne Mergy, Gurvan Lecuyer, Dawa Derksen, Dario Izzo</em>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div><br>
---->

<!-----
<div class="row" id="awards">
  <div class="col-xs-12">
    <h2>Awards</h2>
  </div>
</div>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:30px;" src="{{ "/static/img/bpa.png" | prepend:site.baseurl }}">
    <p>
    <br><br>Improving Astronomy Image Quality Through Real-time Wavefront Estimation <br><em>David Thomas, Joshua Meyers, Steven Kahn</em>
    </p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:30px;" src="{{ "/static/img/bpfa.png" | prepend:site.baseurl }}">
    <p>
    <br><br>AI4MARS: A Dataset for Terrain-Aware Autonomous Driving on Mars<br>
    <em>R. Michael Swan, Deegan J Atha, Henry A Leopold, Cindy Chiu, Matthew Gildner, Stephanie L Oij, Masahiro Ono</em>
    </p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:30px;" src="{{ "/static/img/bpra.png" | prepend:site.baseurl }}">
    <p>
    SPACESeg: Automated Detection of Bed Junction Morphologies Indicating Signs of Life in Ediacaran Period
    <br><em>Padmaja Jonnalagedda, Rachel Surprenant, Mary Droser, Bir Bhanu</em>
    <br>A Monocular Pose Estimation Case Study: The Hayabusa2 Minerva-II2 Deployment
    <br><em>Andrew Price, Kazuya Yoshida</em>
    <br>Vision-based Neural Scene Representations for Spacecraft
    <br><em>Anne Mergy, Gurvan Lecuyer, Dawa Derksen, Dario Izzo</em>
    </p>
  </div>
</div><br>
--->

   
<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call for Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      We solicit papers for AI4Space. Papers will be fully peer reviewed, and accepted papers will be published in the proceedings of ECCV Workshops. Authors of accepted papers will also be invited to present at the workshop at ECCV 2022.
      </p>
      <p>
      The general emphasis of AI4Space is vision and learning algorithms in off-Earth environments, including in the orbital region, surface and underground environments on other planetary bodies (e.g., the moon, Mars and asteroids), interplanetary space and solar system, and distant galaxies. Target application areas include autonomous spacecraft, space robotics, space traffic management, astronomy, astrobiology and cosmology. Emphasis is also placed on novel sensors and processing hardware for vision and learning in space, mitigating the challenges of the space environment towards vision and learning (e.g., solar radiation, extreme temperatures), and solving practical difficulties in vision and learning for space (e.g., lack of training data, unknown or partially known characteristics of operating environments).
    </p>
    <p>
    A specific list of topics is as follows:
    <ul>
      <li>Visual navigation for spacecraft operations (including close proximity rendezvous, docking, space maneuvers, pose estimation, entry descent landing)</li>
      <li>Vision and learning for space robotics</li>
      <li>Positioning, mapping and SLAM for the moon and Mars</li>
      <li>Autonomous celestial positioning</li>
      <li>Space debris monitoring and mitigation</li>
      <li>Vision and learning for astronomy, astrobiology and cosmology</li>
      <li>Sensors for space applications (e.g., optical, multispectral, lidar, radar, event-based)</li>
      <li>AI and learning-based satellite communications and IoT</li>
      <li>Processing hardware for vision and learning in space, including satellite on-board processing</li>
      <li>Mitigating challenges of the space environment to vision and learning</li>
      <li>Datasets, transfer learning and domain gap for space problems</li>
    </ul>
    </p>
  <h3>Peaceful usage of AI for space</h3>
    <p>
    All papers published via this workshop must be aimed towards the peaceful usage of AI for space.
    </p>
    <h3>Submission</h3>  
    <p>
      Submissions should be in the ECCV format and are limited to 8 pages excluding reference.
      Use the <a href="https://drive.google.com/file/d/171-xo72Jx40cZ4qT20ZZsDDKXPIOWnss/view?usp=sharing" download>template</a> for detailed formatting instructions.
      Please refer to the main conference's <a href="https://eccv2022.ecva.net/submission/call-for-papers/">submission guildelines</a> for more details. 
  </p>
    <p>  
      <!----<a href="">Submit your paper via the CMT3 submission system.</a>--->
      Paper submission will be conducted through CMT3 (link TBD).
    </p>
  <p>
    Reviewing is <b>double blind</b> - remember to remove your names and affiliations in the submitted version (selecting the reviewing option in the LaTeX template will take care of that). Accepted works will be published in the ECCV 2022 proceedings.
    </p>
  </div>
</div><br>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
    <p>
    All times/dates below are in Pacific Standard Time.
    </p>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td>
          <td>TBD</td>
        </tr>
        <tr>
          <td>Notification to Authors</td>
          <td>TBD</td>
        </tr>
        <tr>
          <td>Camera-Ready Deadline</td>
          <td>TBD</td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>TBD</td>
        </tr>
      </tbody>
    </table>
  </div>
</div><br>


<br>
<div class="row" id="PCs">
  <div class="col-md-12">
    <h2>Program Committee</h2>
    TBD
  </div>
</div>


<br>
<div class="row" id="sponsors">
  <div class="col-md-12">
    <h2>Sponsors</h2>
    TBD
  </div>
</div>

<!-----
<div class="row">

<div class="col-xs-4">
    <p>
        <div class="col-xs-2">
        </div>
        <div class="col-xs-10">
            <a href="https://www.draper.com/"><img class="people-pic-big" src="{{ "/static/img/sponsors/draper.png" | prepend:site.baseurl }}"></a> 
        </div>
    </p>
    <p>
        At <a href="https://www.draper.com/">Draper</a>, we believe exciting things happen when we combine our diverse disciplines to imagine and create new solutions. From whiteboard concept to fielded systems, Draper engineers design, develop and deploy advanced technology solutions for the world’s most difficult and important problems. More than a thousand engineers and scientists — experts in fields ranging from GN&C to microfabrication — bring a multidisciplinary advantage to system design. The breadth and depth of our expertise enable us to take on almost any challenge. By building and field-testing working prototypes we accelerate design iterations. We can complete small production runs, license our intellectual property and transition technology for large-volume production. We provide full life-cycle support, including technology refresh. We provide engineering services directly to government, commercial companies and academia; work on teams as prime contractor or subcontractor; and participate as a collaborator in consortia. As a not-for-profit engineering innovation company, we provide unbiased assessments of technology or systems designed or recommended by other organizations — whether custom-designed or commercial-off-the-shelf.
    </p>
</div>

<div class="col-xs-4">
    <p>
    <div class="col-xs-2">
    </div>
    <div class="col-xs-10">
        <a href="https://lt.linkedin.com/company/blackswanspace/"><img class="people-pic-big" src="{{ "/static/img/sponsors/blackswan.png" | prepend:site.baseurl }}"></a> 
        </div>
    </p>
    <p>
        <a href="https://lt.linkedin.com/company/blackswanspace/">Blackswan Technologies</a> is making satellites autonomous. The company’s products are designed to manage the expected ten-fold increase in space traffic in the coming years by lowering collision risk, reducing costs of operations and expanding the range of autonomous activities in orbit. Our ultimate goal is to help build a self sustaining market economy where complex tasks such as debris removal, on-orbit servicing and construction can be performed by using autonomous satellites.
        </p>
</div>

<div class="col-xs-4">
    <p>
    <div class="col-xs-2">
    </div>
    <div class="col-xs-10">
    <a href="https://www.space.gov.au/"><img class="people-pic-big" src="{{ "/static/img/sponsors/asa.png" | prepend:site.baseurl }}"></a>
    </div>
    </p>
    <p>
    The <a href="https://www.space.gov.au/">Australian Space Agency</a> will transform and grow a globally respected Australian space industry that lifts the broader economy, inspires and improves the lives of Australians – underpinned by strong international and national engagement.
    </p>
</div>

</div>
---->

<!----
<br>
<div class="row" id="organisations">
  <div class="col-md-12">
    <h2>Affiliated Organisations</h2>
    TBD
  </div>
</div>
--->

<!-----
<div class="row">

<div class="col-xs-4">
    <p>
    <div class="col-xs-2">
    </div>
    <div class="col-xs-10">
    <a href="https://www.esa.int/"><img class="people-pic-big" src="{{ "/static/img/sponsors/esa.png" | prepend:site.baseurl }}"></a>
    </div>
    </p>
    <p>
    The <a href="https://www.esa.int/">European Space Agency (ESA)</a> is Europe’s gateway to space. Its mission is to shape the development of Europe’s space capability and ensure that investment in space continues to deliver benefits to the citizens of Europe and the world.
    </p>
</div>

<div class="col-xs-4">
    <p>
    <div class="col-xs-2">
    </div>
    <div class="col-xs-10">
    <a href="https://www.esa.int/gsp/ACT/"><img class="people-pic-big" src="{{ "/static/img/sponsors/act.png" | prepend:site.baseurl }}"></a>
    </div>
    </p>
    <p>
    The <a href="https://www.esa.int/gsp/ACT/">Advanced Concepts Team (ACT)</a> is part of the ESA's Directorate of Technical and Quality Management (TEC-SF). The team is essentially a channel for the study of technologies and ideas that are of strategical importance in the long term planning of ESA. It serves the function of a think tank providing decision makers the support of a highly multidisciplinary research group. Science and engineering research fellows (PhDs working at ESA for 2 years), Young Graduate Trainee and stagiaires form the bulk of this Team. Based at ESTEC, they carry out research work on advanced topics and emerging technologies and perform highly skilled analysis on a wide range of topics.
    </p>
</div>

<div class="col-xs-4">
    <p>
    <div class="col-xs-2">
    </div>
    <div class="col-xs-10">
    <a href="https://smartsatcrc.com/"><img class="people-pic-big" src="{{ "/static/img/sponsors/smartsat_crc.png" | prepend:site.baseurl }}"></a>
    </div>
    </p>
    <p>
    The <a href="https://smartsatcrc.com/">SmartSat CRC</a> is a consortium of universities and other research organisations, partnered with industry that has been funded by the Australian Government to develop know-how and technologies in advanced telecommunications and IoT connectivity, intelligent satellite systems and Earth observation next generation data services. The impact of this research will be to develop intellectual property and a specialist industry expertise that will spawn new businesses, create export economic value and generate new high-tech jobs for all Australians.
    </p>
</div>

</div>
--->

<hr>

<br>

